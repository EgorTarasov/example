{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Record:\n",
    "    src: str\n",
    "    content: str\n",
    "    chunk_id: int\n",
    "    attachments: list[tuple[str, str]]\n",
    "    html_page: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf(url: str) -> list[Record]:\n",
    "    request = requests.get(url)\n",
    "    content = request.content\n",
    "    pdf_file = fitz.open(\"pdf\", content)\n",
    "\n",
    "    result = []\n",
    "        \n",
    "    for page_index in range(len(pdf_file)):\n",
    "        page_content = pdf_file.load_page(page_index).get_text().replace('\\n', '')\n",
    "        result.append(Record(src='', content=page_content, chunk_id=(page_index + 1), attachments=[], html_page=''))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_url = \"https://arxiv.org/pdf/2312.10997\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parse_pdf(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3Fig. 2. A representative instance of the RAG process applied to question answering. It mainly consists of 3 steps. 1) Indexing. Documents are split into chunks,encoded into vectors, and stored in a vector database. 2) Retrieval. Retrieve the Top k chunks most relevant to the question based on semantic similarity. 3)Generation. Input the original question and the retrieved chunks together into LLM to generate the final answer.widespread adoption of ChatGPT. The Naive RAG followsa traditional process that includes indexing, retrieval, andgeneration, which is also characterized as a “Retrieve-Read”framework [7].Indexing starts with the cleaning and extraction of raw datain diverse formats like PDF, HTML, Word, and Markdown,which is then converted into a uniform plain text format. Toaccommodate the context limitations of language models, textis segmented into smaller, digestible chunks. Chunks are thenencoded into vector representations using an embedding modeland stored in vector database. This step is crucial for enablingefficient similarity searches in the subsequent retrieval phase.Retrieval. Upon receipt of a user query, the RAG systememploys the same encoding model utilized during the indexingphase to transform the query into a vector representation.It then computes the similarity scores between the queryvector and the vector of chunks within the indexed corpus.The system prioritizes and retrieves the top K chunks thatdemonstrate the greatest similarity to the query. These chunksare subsequently used as the expanded context in prompt.Generation. The posed query and selected documents aresynthesized into a coherent prompt to which a large languagemodel is tasked with formulating a response. The model’sapproach to answering may vary depending on task-specificcriteria, allowing it to either draw upon its inherent parametricknowledge or restrict its responses to the information con-tained within the provided documents. In cases of ongoingdialogues, any existing conversational history can be integratedinto the prompt, enabling the model to engage in multi-turndialogue interactions effectively.However, Naive RAG encounters notable drawbacks:Retrieval Challenges. The retrieval phase often struggleswith precision and recall, leading to the selection of misalignedor irrelevant chunks, and the missing of crucial information.Generation Difficulties. In generating responses, the modelmay face the issue of hallucination, where it produces con-tent not supported by the retrieved context. This phase canalso suffer from irrelevance, toxicity, or bias in the outputs,detracting from the quality and reliability of the responses.Augmentation Hurdles. Integrating retrieved informationwith the different task can be challenging, sometimes resultingin disjointed or incoherent outputs. The process may alsoencounter redundancy when similar information is retrievedfrom multiple sources, leading to repetitive responses. Deter-mining the significance and relevance of various passages andensuring stylistic and tonal consistency add further complexity.Facing complex issues, a single retrieval based on the originalquery may not suffice to acquire adequate context information.Moreover, there’s a concern that generation models mightoverly rely on augmented information, leading to outputs thatsimply echo retrieved content without adding insightful orsynthesized information.B. Advanced RAGAdvanced RAG introduces specific improvements to over-come the limitations of Naive RAG. Focusing on enhancing re-trieval quality, it employs pre-retrieval and post-retrieval strate-gies. To tackle the indexing issues, Advanced RAG refinesits indexing techniques through the use of a sliding windowapproach, fine-grained segmentation, and the incorporation ofmetadata. Additionally, it incorporates several optimizationmethods to streamline the retrieval process [8].'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2].chunk_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
